# Awesome Multimodal Large Language Models Hallucination Mitigation
This is a list of some awesome works on mitigating hallucination in large multimodal models.



## :books:Survey

1. [Hallucination of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2404.18930) (Apr. 30, 2024)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2404.18930)[![github](https://img.shields.io/github/stars/showlab/Awesome-MLLM-Hallucination)](https://github.com/showlab/Awesome-MLLM-Hallucination/)



## :bar_chart:Benchmarks

1. [Object Hallucination in Image Captioning](https://arxiv.org/abs/1809.02156) ](https://arxiv.org/abs/2404.18930) (Sep. 6, 2018, **EMNLP 2018**) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/1809.02156)![alias](https://img.shields.io/badge/CHAIR-black)
2. [Evaluating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2305.10355) (May. 17, 2023, **EMNLP 2023**) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.10355)[![github](https://img.shields.io/github/stars/AoiDragon/POPE)](https://github.com/AoiDragon/POPE)![alias](https://img.shields.io/badge/PoPE-black)
3. [Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs](https://arxiv.org/abs/2401.06209) (Jan. 11, 2024, **CVPR 2024**) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.10355)[![github](https://img.shields.io/github/stars/tsb0601/MMVP)](https://github.com/tsb0601/MMVP)![alias](https://img.shields.io/badge/MMVP-black)
4. [MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2306.13394) (Jun. 23, 2023) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2306.13394)[![github](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models)](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)![alias](https://img.shields.io/badge/MME-black)



## :clap:Hallucination Mitigation

1. [Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2311.16922) (Nov. 28, 2023, **CVPR 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.16922)[![github](https://img.shields.io/github/stars/DAMO-NLP-SG/VCD)](https://github.com/DAMO-NLP-SG/VCD)![tag](https://img.shields.io/badge/Highlight-FF4D00)![alias](https://img.shields.io/badge/VCD-black)
2. [OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation](https://arxiv.org/abs/2311.17911) (Nov. 29, 2023, **CVPR 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2311.17911)[![github](https://img.shields.io/github/stars/shikiw/OPERA)](https://github.com/shikiw/OPERA)![tag](https://img.shields.io/badge/Highlight-FF4D00)![alias](https://img.shields.io/badge/OPERA-black)
3. [Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://arxiv.org/abs/2403.18715) (mAR. 27, 2024, **ACL 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2403.18715)![alias](https://img.shields.io/badge/ICD-black)
4. [DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models](https://arxiv.org/abs/2309.03883) (Sep. 7, 2023, **ICLR 2024**) 
5. [Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs](https://arxiv.org/abs/2401.06209) (Jan. 11, 2024, **CVPR 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.10355)[![github](https://img.shields.io/github/stars/tsb0601/MMVP)](https://github.com/tsb0601/MMVP)![alias](https://img.shields.io/badge/MoF-black)
6. [Mitigating Object Hallucination via Concentric Causal Attention](https://arxiv.org/abs/2410.15926) (Oct. 21, 2024, **NeurIPS 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.15926)[![github](https://img.shields.io/github/stars/xing0047/cca-llava)](https://github.com/xing0047/cca-llava)![alias](https://img.shields.io/badge/CCA-black)
7. [DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination](https://arxiv.org/abs/2410.04514) (Oct. 6, **EMNLP 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.04514)![alias](https://img.shields.io/badge/DAMRO-black)
8. [VASparse: Towards Efficient Visual Hallucination Mitigation for Large Vision-Language Model via Visual-Aware Sparsification](https://arxiv.org/abs/2501.06553) (Jan. 11, 2025, **CVPR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2501.06553)[![github](https://img.shields.io/github/stars/mengchuang123/VASparse-github)](https://github.com/mengchuang123/VASparse-github)![alias](https://img.shields.io/badge/VASparse-black)
9. [Mitigating Object Hallucinations in Large Vision-Language Models with Assembly of Global and Local Attention](https://arxiv.org/abs/2406.12718) (Jun. 18, 2024, **CVPR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2406.12718)[![github](https://img.shields.io/github/stars/Lackel/AGLA)](https://github.com/Lackel/AGLA)![alias](https://img.shields.io/badge/AGLA-black)
10. [Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models](http://arxiv.org/abs/2408.02032) (Aug. 4, 2024, **ICLR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2406.12718)[![github](https://img.shields.io/github/stars/huofushuo/SID)](https://github.com/huofushuo/SID)![alias](https://img.shields.io/badge/SID-black)
11. [PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training](https://arxiv.org/abs/2503.06486) (Mar. 9, 2025, **ICLR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.06486)![tag](https://img.shields.io/badge/Spotlight-FF4D00)![alias](https://img.shields.io/badge/PerturboLLaVA-black)
12. [Interpreting and Editing Vision-Language Representations to Mitigate Hallucinations](https://arxiv.org/abs/2410.02762) (Oct. 3, 2024, **ICLR 2025**) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.02762)[![github](https://img.shields.io/github/stars/nickjiang2378/vl-interp)](https://github.com/nickjiang2378/vl-interp/)
13. [Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders](https://arxiv.org/abs/2408.15998) (Aug. 28, 2024, **ICLR 2025**) [![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2408.15998)[![github](https://img.shields.io/github/stars/NVlabs/Eagle)](https://github.com/NVlabs/Eagle)![alias](https://img.shields.io/badge/Eagle-black)
14. [Octopus: Alleviating Hallucination via Dynamic Contrastive Decoding](https://arxiv.org/abs/2503.00361) (Mar. 1, 2025, **CVPR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2503.00361)[![github](https://img.shields.io/github/stars/LijunZhang01/Octopus)](https://github.com/LijunZhang01/Octopus)![alias](https://img.shields.io/badge/Octopus-black)
15. [Refine Knowledge of Large Language Models via Adaptive Contrastive Learning](http://arxiv.org/abs/2502.07184) (Feb. 11, 2025, **ICLR 2025**)![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2502.07184)
16. [Alleviating Hallucinations in Large Vision-Language Models through Hallucination-Induced Optimization](http://arxiv.org/abs/2405.15356) (May. 24, 2024, **NeurIPS 2024**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](http://arxiv.org/abs/2405.15356)[![github](https://img.shields.io/github/stars/BT-C/HIO)](https://github.com/BT-C/HIO)![alias](https://img.shields.io/badge/HIO-black)
17. [Reducing Hallucinations in Vision-Language Models via Latent Space Steering](https://arxiv.org/abs/2410.15778) (Oct. 21, 2024, **ICLR 2025**)[![arxiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2410.15778)![tag](https://img.shields.io/badge/Spotlight-FF4D00)![alias](https://img.shields.io/badge/VTI-black)





## :star:Acknowledgment

This project is inspired by [Awesome-MLLM-Hallucination](https://github.com/showlab/Awesome-MLLM-Hallucination) and [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models). Thanks for their contribution to the research community.
